{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nanodegree Engenheiro de Machine Learning\n",
    "## Aprendizagem Supervisionada\n",
    "## Project 2: Construindo um Sistema de Intervenção para Estudantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bem-vindo ao segundo projeto do Nanodegree de Machine Learning! Neste Notebook, alguns templates de código já foram fornecidos, e será o seu trabalho implementar funcionalidades necessárias para completar este projeto com êxito. Seções que começam com **'Implementação'** no cabeçalho indicam que o bloco de código que se segue precisará de funcionalidades adicionais que você deve fornecer. Instruções serão providenciadas para cada seção e as especificações para cada implementação estarão marcadas no bloco de código com o comando `'TODO'`. Tenha certeza de ler atentamente todas as instruções!\n",
    "\n",
    "Além do código implementado, haverá questões relacionadas ao projeto e à implementação que você deve responder. Cada seção em que você tem que responder uma questão será antecedida de um cabeçalho **'Questão X'**. Leia atentamente cada questão e escreva respostas completas nas caixas de texto subsequentes que começam com **'Resposta: '**. O projeto enviado será avaliado baseado nas respostas para cada questão e a implementação que você forneceu.  \n",
    "\n",
    ">**Nota:** Células de código e Markdown podem ser executadas utilizando o atalho de teclado **Shift + Enter**. Além disso, as células Markdown podem ser editadas, um clique duplo na célula entra no modo de edição."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 1 - Classificação versus Regressão\n",
    "*Seu objetivo neste projeto é identificar estudantes que possam precisar de intervenção antecipada antes de serem reprovados. Que tipo de problema de aprendizagem supervisionada é esse: classificação ou regressão? Por quê?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: ** \n",
    "O tipo de problema de aprendizagem supervisionada é classificação. Dado uma coleção de estudantes o problema visa identificar aqueles que podem precisar de intervenção antecipada e aqueles que não podem precisar, ou seja, será necessário rotular se determinado estudante sofrerá intervenção ou não, baseado nos dados dos atributos. Logo, a saída do classificador será binária (discreta), ou seja, sim ou não. Mostrando que é um problema de classificação."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observando os Dados\n",
    "Execute a célula de código abaixo para carregar as bibliotecas de Python necessárias e os dados sobre os estudantes. Note que a última coluna desse conjunto de dados, `'passed'`, será nosso rótulo alvo (se o aluno foi ou não aprovado). As outras colunas são atributos sobre cada aluno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os dados dos estudantes foram lidos com êxito!\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from time import time\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Ler os dados dos estudantes\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Os dados dos estudantes foram lidos com êxito!\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Observando os Dados\n",
    "Vamos começar observando o conjunto de dados para determinar quantos são os estudantes sobre os quais temos informações e entender a taxa de graduação entre esses estudantes. Na célula de código abaixo, você vai precisar calcular o seguinte:\n",
    "- O número total de estudantes, `n_students`.\n",
    "- O número total de atributos para cada estudante, `n_features`.\n",
    "- O número de estudantes aprovados, `n_passed`.\n",
    "- O número de estudantes reprovados, `n_failed`.\n",
    "- A taxa de graduação da classe, `grad_rate`, em porcentagem (%).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número total de estudantes: 395\n",
      "Número de atributos: 30\n",
      "Número de estudantes aprovados: 265\n",
      "Número de estudantes reprovados: 130\n",
      "Taxa de graduação: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Calcule o número de estudante\n",
    "n_students = len(student_data)\n",
    "\n",
    "# TODO: Calcule o número de atributos\n",
    "n_features = len(student_data.columns)-1\n",
    "\n",
    "# TODO: Calcule o número de alunos aprovados\n",
    "n_passed = student_data.passed.value_counts()['yes']\n",
    "\n",
    "# TODO: Calcule o número de alunos reprovados\n",
    "n_failed = student_data.passed.value_counts()['no']\n",
    "\n",
    "# TODO: Calcule a taxa de graduação\n",
    "grad_rate = (n_passed*1.0 / n_students)*100.0\n",
    "\n",
    "# Imprima os resultados\n",
    "print \"Número total de estudantes: {}\".format(n_students)\n",
    "print \"Número de atributos: {}\".format(n_features)\n",
    "print \"Número de estudantes aprovados: {}\".format(n_passed)\n",
    "print \"Número de estudantes reprovados: {}\".format(n_failed)\n",
    "print \"Taxa de graduação: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparando os Dados\n",
    "Nesta seção, vamos preparara os dados para modelagem, treinamento e teste.\n",
    "\n",
    "### Identificar atributos e variáveis-alvo\n",
    "É comum que os dados que você obteve contenham atributos não numéricos. Isso pode ser um problema, dado que a maioria dos algoritmos de machine learning esperam dados númericos para operar cálculos.\n",
    "\n",
    "Execute a célula de código abaixo para separar os dados dos estudantes em atributos e variáveis-alvo e verificar se algum desses atributos é não numérico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colunas de atributos:\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "\n",
      "Coluna-alvo: passed\n",
      "\n",
      "Feature values:\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extraia as colunas dos atributo\n",
    "feature_cols = list(student_data.columns[:-1])\n",
    "\n",
    "# Extraia a coluna-alvo, 'passed'\n",
    "target_col = student_data.columns[-1] \n",
    "\n",
    "# Mostre a lista de colunas\n",
    "print \"Colunas de atributos:\\n{}\".format(feature_cols)\n",
    "print \"\\nColuna-alvo: {}\".format(target_col)\n",
    "\n",
    "# Separe os dados em atributos e variáveis-alvo (X_all e y_all, respectivamente)\n",
    "X_all = student_data[feature_cols]\n",
    "y_all = student_data[target_col]\n",
    "\n",
    "# Mostre os atributos imprimindo as cinco primeiras linhas\n",
    "pd.set_option('expand_frame_repr', True)\n",
    "print \"\\nFeature values:\"\n",
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pré-processar Colunas de Atributo\n",
    "\n",
    "Como você pode ver, há muitas colunas não numéricas que precisam ser convertidas! Muitas delas são simplesmente `yes`/`no`, por exemplo, a coluna `internet`. É razoável converter essas variáveis em valores (binários) `1`/`0`.\n",
    "\n",
    "Outras colunas, como `Mjob` e `Fjob`, têm mais do que dois valores e são conhecidas como variáveis categóricas. A maneira recomendada de lidar com esse tipo de coluna é criar uma quantidade de colunas proporcional aos possíveis valores (por exemplo, `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc), e assinalar `1` para um deles e `0` para todos os outros.\n",
    "\n",
    "Essas colunas geradas são por vezes chamadas de _variáveis postiças_ (em inglês: _dummy variables_), e nós iremos utilizar a função [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) para fazer essa conversão. Execute a célula de código abaixo para executar a rotina de pré-processamento discutida nesta seção."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48 total features):\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "   school_GP  school_MS     sex_F  sex_M       age  address_R  address_U  \\\n",
      "0   0.046424        0.0  0.046424    0.0  0.835629        0.0   0.046424   \n",
      "1   0.051434        0.0  0.051434    0.0  0.874386        0.0   0.051434   \n",
      "2   0.049629        0.0  0.049629    0.0  0.744438        0.0   0.049629   \n",
      "3   0.055989        0.0  0.055989    0.0  0.839839        0.0   0.055989   \n",
      "4   0.052200        0.0  0.052200    0.0  0.835193        0.0   0.052200   \n",
      "\n",
      "   famsize_GT3  famsize_LE3  Pstatus_A    ...       higher  internet  \\\n",
      "0     0.046424     0.000000   0.046424    ...     0.046424  0.000000   \n",
      "1     0.051434     0.000000   0.000000    ...     0.051434  0.051434   \n",
      "2     0.000000     0.049629   0.000000    ...     0.049629  0.049629   \n",
      "3     0.055989     0.000000   0.000000    ...     0.055989  0.055989   \n",
      "4     0.052200     0.000000   0.000000    ...     0.052200  0.000000   \n",
      "\n",
      "   romantic    famrel  freetime     goout      Dalc      Walc    health  \\\n",
      "0  0.000000  0.185695  0.139272  0.185695  0.046424  0.046424  0.139272   \n",
      "1  0.000000  0.257172  0.154303  0.154303  0.051434  0.051434  0.154303   \n",
      "2  0.000000  0.198517  0.148888  0.099258  0.099258  0.148888  0.148888   \n",
      "3  0.055989  0.167968  0.111979  0.111979  0.055989  0.055989  0.279946   \n",
      "4  0.000000  0.208798  0.156599  0.104399  0.052200  0.104399  0.260998   \n",
      "\n",
      "   absences  \n",
      "0  0.278543  \n",
      "1  0.205738  \n",
      "2  0.496292  \n",
      "3  0.111979  \n",
      "4  0.208798  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "def preprocess_features(X):\n",
    "    ''' Pré-processa os dados dos estudantes e converte as variáveis binárias não numéricas em\n",
    "        variáveis binárias (0/1). Converte variáveis categóricas em variáveis postiças. '''\n",
    "    \n",
    "    # Inicialize nova saída DataFrame\n",
    "    output = pd.DataFrame(index = X.index)\n",
    "\n",
    "    # Observe os dados em cada coluna de atributos \n",
    "    for col, col_data in X.iteritems():\n",
    "        \n",
    "        # Se o tipo de dado for não numérico, substitua todos os valores yes/no por 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "\n",
    "        # Se o tipo de dado for categórico, converta-o para uma variável dummy\n",
    "        if col_data.dtype == object:\n",
    "            # Example: 'school' => 'school_GP' and 'school_MS'\n",
    "            col_data = pd.get_dummies(col_data, prefix = col)  \n",
    "        \n",
    "        # Reúna as colunas revisadas\n",
    "        output = output.join(col_data)\n",
    "    \n",
    "    return output\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "\n",
    "# ******* Normaliza os dados **********\n",
    "normer = Normalizer()\n",
    "X = normer.fit_transform(X_all.values)\n",
    "X_all = pd.DataFrame(data=X, columns=list(X_all.columns))\n",
    "\n",
    "print \"Processed feature columns ({} total features):\\n{}\".format(len(X_all.columns), list(X_all.columns))\n",
    "print X_all.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Divisão dos Dados de Treinamento e Teste\n",
    "Até agora, nós convertemos todos os atributos _categóricos_ em valores numéricos. Para o próximo passo, vamos dividir os dados (tanto atributos como os rótulos correspondentes) em conjuntos de treinamento e teste. Na célula de código abaixo, você irá precisar implementar o seguinte:\n",
    "- Embaralhe aleatoriamente os dados (`X_all`, `y_all`) em subconjuntos de treinamento e teste.\n",
    "  - Utilizar 300 pontos de treinamento (aproxidamente 75%) e 95 pontos de teste (aproximadamente 25%).\n",
    "  - Estabelecer um `random_state` para as funções que você utiliza, se a opção existir.\n",
    "  - Armazene os resultados em `X_train`, `X_test`, `y_train` e `y_test`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O conjunto de treinamento tem 300 amostras.\n",
      "O conjunto de teste tem 95 amostras.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe qualquer funcionalidade adicional de que você possa precisar aqui\n",
    "from sklearn import cross_validation\n",
    "\n",
    "# TODO: Estabeleça o número de pontos de treinamento\n",
    "num_train = 300\n",
    "\n",
    "# Estabeleça o número de pontos de teste\n",
    "num_test = X_all.shape[0] - num_train\n",
    "\n",
    "# TODO: Emabaralhe e distribua o conjunto de dados de acordo com o número de pontos de treinamento e teste abaixo\n",
    "X_train, X_test, y_train, y_test = cross_validation.train_test_split(\\\n",
    "X_all, y_all, stratify=y_all, train_size=num_train, test_size=num_test, random_state=0)\n",
    "\n",
    "# Mostre o resultado da distribuição\n",
    "print \"O conjunto de treinamento tem {} amostras.\".format(X_train.shape[0])\n",
    "print \"O conjunto de teste tem {} amostras.\".format(X_test.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Treinando e Avaliando Modelos\n",
    "Nesta seção, você irá escolher 3 modelos de aprendizagem supervisionada que sejam apropriados para esse problema e que estejam disponíveis no `scikit-learn`. Primeiro você irá discutir o raciocínio por trás da escolha desses três modelos considerando suas vantagens e desvantagens e o que você sabe sobre os dados. Depois você irá ajustar o modelo a diferentes tamanhos de conjuntos de treinamento (com 100, 200 e 300 pontos) e medir a pontuação F<sub>1</sub>. Você vai precisar preencher três tabelas (uma para cada modelo) que mostrem o tamanho do conjunto de treinamento, o tempo de treinamento, o tempo de previsão e a pontuação F<sub>1</sub> no conjunto de treinamento.\n",
    "\n",
    "**Os seguintes modelos de aprendizagem supervisionada estão atualmente disponíveis no **[`scikit-learn`](http://scikit-learn.org/stable/supervised_learning.html)** para você escolher:**\n",
    "- Gaussian Naive Bayes (GaussianNB)\n",
    "- Árvores de Decisão\n",
    "- Métodos de agregação (Bagging, AdaBoost, Random Forest, Gradient Boosting)\n",
    "- K-Nearest Neighbors (KNeighbors)\n",
    "- Método do gradiente estocástico (SGDC)\n",
    "- Máquinas de vetores de suporte (SVM)\n",
    "- Regressão logística"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 2 - Aplicação dos Modelos\n",
    "*Liste três modelos de aprendizagem supervisionada que são apropriadas para esse problema. Para cada modelo escolhido:*\n",
    "- Descreva uma aplicação em mundo real na indústria em que o modelo pode ser aplicado. *(Talvez você precise fazer um pouco de pesquisa para responder essa questão – dê as devidas referências!)* \n",
    "- Quais são as vantagens do modelo; quando ele tem desempenho melhor? \n",
    "- Quais são as desvantagens do modelo, quando ele tem desempenho pior?\n",
    "- O que faz desse modelo um bom candidato para o problema, considerando o que você sabe sobre os dados?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "Os três modelos escolhidos são: Gaussian Naive Bayes (GaussianNB), Árvores de Decisão e Máquinas de vetores de suporte (SVM). Os três modelos, além de serem modelos que lidam com problemas de classificação binária, como é o caso, conseguem lidar com um maior número de features (atributos) e, mesmo aplicados em um conjunto de dados pequeno, conseguem obter valores bons valores de acuracidade para esse tipo de classificação.  \n",
    "\n",
    "1 . GaussianNB\n",
    "\n",
    "   1.1. Aplicação: detecção de spam de perfis em redes sociais. Esse problema consiste em identificar se perfis em redes sociais são realmente reais baseado nas informaçoes repassadas no perfil e no timeline. NB é usado para resolver esse problema de forma similar como é usado tradicionamente para detectar spam de emails. Fonte: http://theory.stanford.edu/~dfreeman/papers/namespam.pdf\n",
    "    \n",
    "   1.2. Vantagens: seu algoritmo é simples, tem ótimo desempenho computacional, principalemte na fase de treino, converge mais rápido por isso exige um tamanho de treino menor. \n",
    "    \n",
    "   1.3. Desvantagens: não pode ser aplicados em conjunto de dados onde os atributos (features) sejam dependentes, como por exemplos uma hierarquia ou uma relação entre atributos, pois o modelo assume como premissa a forte condicional independência entre os atributos. \n",
    "    \n",
    "   1.4. Candidato ao problema: é um bom candidato pois o conjunto de dados é pequeno, seus atributos são independentes e a saída do problema é binária.\n",
    "    \n",
    "    \n",
    "2 . Árvore de Decisão\n",
    "\n",
    "   2.1. Aplicação: área de finanças. Como por exemplo, em precificação de produtos de acordo com a data de vencimento, levando em consideração atributos como quantidade de estoque, tipo de venda, local da venda, data, preço atual. Fonte: http://www.investopedia.com/articles/financial-theory/11/decisions-trees-finance.asp \n",
    "    \n",
    "   2.2. Vantagens: fácil de interpretar, de explicar e tem boa expressividade. Lidam bem com muitos atributos, sejam discretos ou contínuos, mesmo se os dados não são linearmente separáveis. Apresentam, em média, alta acurácia. \n",
    "    \n",
    "   2.3. Desvantagens: tendem a sobreajustar, principalmente quando há uma grande quantidade de atributos e as árvores geradas são complexas. Não lida bem com reaprendizado ou reforço, ou seja, toda vez que a árvore tiver que aprender com novos exemplos de treino ela terá que ser reconstruída.\n",
    "    \n",
    "   2.4. Candidato ao problema: é um bom cadidato pois há muitos atributos e eles são discretos, os dados dos atributos estão limpos (pouco ruído e pouca ausência nos dados), e a saída do problema é binária.\n",
    "    \n",
    "    \n",
    "3 . SVM\n",
    "\n",
    "   3.1. Aplicação: avaliação de risco de crédito. Análise e avaliação de risco de crédito é uma atividade crucial na rede de bancos publica e privada, pois os bancos precisam discriminar os bons dos maus credores. SVM é amplamente utilizado nessa tarefa de classificação. Fonte: https://www.computer.org/csdl/proceedings/gcis/2009/3571/04/3571d049.pdf\n",
    "    \n",
    "   3.2. Vantagens: ideais a serem aplicados em domínios onde há clara margem de separação dos dados que se quer classificar. Capacidade de lidar com conjuntos de dados complexo, com muitas dimensões, como por exemplo, obtém altos valores de acurária quando aplicados para classificação de textos em espaços de alta dimensão. Pouco overfitting em conjunto de dados limpos.  \n",
    "    \n",
    "   3.3. Desvantagens: difíceis de interpretar, consomem muita memória, não trabalham bem em grandes conjuntos de dados, pois o tempo computacional do treino é alto. Não funciona bem em conjunto de dados com grande quantidade de ruídos. \n",
    "    \n",
    "   3.4. Candidato ao problema: é um bom candidato pois o conjunto de dados é pequeno, está com pouco ruído, os valores dos atributos são discretos e a saída do modelo é binária.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração\n",
    "Execute a célula de código abaixo para inicializar três funções de ajuda que você pode utilizar para treinar e testar os três modelos de aprendizagem supervisionada que você escolheu acima. As funções são as seguintes:\n",
    "- `train_classifier` - recebe como parâmetro um classificador e dados de treinamento e ajusta o classificador aos dados.\n",
    "- `predict_labels` - recebe como parâmetro um classificador ajustado, atributos e rótulo alvo e faz estimativas utilizando a pontuação do F<sub>1</sub>.\n",
    "- `train_predict` - recebe como entrada um classificador, e dados de treinamento e teste, e executa `train_clasifier` e `predict_labels`.\n",
    " - Essa função vai dar a pontuação F<sub>1</sub> tanto para os dados de treinamento como para os de teste, separadamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def train_classifier(clf, X_train, y_train):\n",
    "    ''' Ajusta um classificador para os dados de treinamento. '''\n",
    "    \n",
    "    # Inicia o relógio, treina o classificador e, então, para o relógio\n",
    "    start = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados\n",
    "    t = end - start\n",
    "    #print \"O modelo foi treinado em {:.4f} segundos\".format(t)\n",
    "    return t\n",
    "\n",
    "    \n",
    "def predict_labels(clf, features, target):\n",
    "    ''' Faz uma estimativa utilizando um classificador ajustado baseado na pontuação F1. '''\n",
    "    \n",
    "    # Inicia o relógio, faz estimativas e, então, o relógio para\n",
    "    start = time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time()\n",
    "    \n",
    "    # Imprime os resultados de retorno\n",
    "    t = end - start\n",
    "    #print \"As previsões foram feitas em {:.4f} segundos.\".format(t)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes'), t\n",
    "\n",
    "\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test):\n",
    "    ''' Treina e faz estimativas utilizando um classificador baseado na pontuação do F1. '''\n",
    "    ltime = []\n",
    "    \n",
    "    # Indica o tamanho do classificador e do conjunto de treinamento\n",
    "    #print \"Treinando um {} com {} pontos de treinamento. . .\".format(clf.__class__.__name__, len(X_train))\n",
    "    \n",
    "    # Treina o classificador\n",
    "    ltime.append(train_classifier(clf, X_train, y_train))\n",
    "    \n",
    "    # Imprime os resultados das estimativas de ambos treinamento e teste\n",
    "    f1t, time = predict_labels(clf, X_train, y_train)\n",
    "    ltime.append(time)\n",
    "    #print \"Pontuação F1 para o conjunto de treino: {:.4f}.\".format(f1t)\n",
    "    f1tt, time = predict_labels(clf, X_test, y_test)\n",
    "    ltime.append(time)\n",
    "    #print \"Pontuação F1 para o conjunto de teste: {:.4f}.\".format(f1tt)\n",
    "    #print \"\"\n",
    "    ltime.extend([f1t,f1tt])\n",
    "    ltime.insert(0,clf.__class__.__name__)    \n",
    "    ltime.insert(1,len(X_train))\n",
    "    return ltime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Métricas de Desempenho do Modelo\n",
    "Com as funções acima, você vai importar os três modelos de aprendizagem supervisionada de sua escolha e executar a função `train_prediction` para cada um deles. Lembre-se de que você vai precisar treinar e usar cada classificador para três diferentes tamanhos de conjuntos de treinamentos: 100, 200 e 300 pontos. Então você deve ter 9 saídas diferentes abaixo – 3 para cada modelo utilizando cada tamanho de conjunto de treinamento. Na célula de código a seguir, você deve implementar o seguinte:\n",
    "- Importe os três modelos de aprendizagem supervisionada que você escolheu na seção anterior.\n",
    "- Inicialize os três modelos e armazene eles em `clf_A`, `clf_B` e `clf_C`.\n",
    " - Defina um `random_state` para cada modelo, se a opção existir.\n",
    " - **Nota:** Utilize as configurações padrão para cada modelo – você vai calibrar um modelo específico em uma seção posterior.\n",
    "- Crie diferentes tamanhos de conjuntos de treinamento para treinar cada modelo.\n",
    " - *Não embaralhe e distribua novamente os dados! Os novos pontos de treinamento devem ser tirados de `X_train` e `y_train`.*\n",
    "- Treine cada modelo com cada tamanho de conjunto de treinamento e faça estimativas com o conjunto de teste (9 vezes no total).  \n",
    "**Nota:** Três tabelas são fornecidas depois da célula de código a seguir, nas quais você deve anotar seus resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      CLF  QTD  Tempo_Treinamento  T_Est_Treino  T_Est_Teste  F1_Treino  F1_Teste\n",
      "0              GaussianNB  100              0.002         0.001        0.000   0.553191  0.612245\n",
      "1              GaussianNB  200              0.002         0.001        0.001   0.829630  0.766917\n",
      "2              GaussianNB  300              0.001         0.001        0.000   0.792176  0.738462\n",
      "3  DecisionTreeClassifier  100              0.002         0.000        0.000   1.000000  0.770370\n",
      "4  DecisionTreeClassifier  200              0.003         0.001        0.000   1.000000  0.725806\n",
      "5  DecisionTreeClassifier  300              0.006         0.000        0.001   1.000000  0.666667\n",
      "6                     SVC  100              0.001         0.001        0.001   0.795181  0.805031\n",
      "7                     SVC  200              0.004         0.002        0.001   0.805970  0.805031\n",
      "8                     SVC  300              0.007         0.005        0.002   0.802395  0.805031\n",
      "                        Média  Tempo_Treinamento  T_Est_Treino  T_Est_Teste  F1_Treino  F1_Teste\n",
      "CLF                                                                                             \n",
      "DecisionTreeClassifier    200           0.003667      0.000333     0.000333   1.000000  0.720948\n",
      "GaussianNB                200           0.001667      0.001000     0.000333   0.724999  0.705875\n",
      "SVC                       200           0.004000      0.002667     0.001333   0.801182  0.805031\n",
      "                        Máximo  Tempo_Treinamento  T_Est_Treino  T_Est_Teste  F1_Treino  F1_Teste\n",
      "CLF                                                                                              \n",
      "DecisionTreeClassifier     300              0.006         0.001        0.001    1.00000  0.770370\n",
      "GaussianNB                 300              0.002         0.001        0.001    0.82963  0.766917\n",
      "SVC                        300              0.007         0.005        0.002    0.80597  0.805031 \n",
      "\n",
      "SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='rbf',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe os três modelos de aprendizagem supervisionada do sklearn\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib #only needed to determine Matplotlib version number\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# TODO: Inicialize os três modelos\n",
    "clf_A = GaussianNB()\n",
    "clf_B = tree.DecisionTreeClassifier(random_state=0)\n",
    "clf_C = svm.SVC(random_state=0)\n",
    "\n",
    "ldata = []\n",
    "for clf in [clf_A,clf_B,clf_C]:\n",
    "    for size in [100,200,300]:\n",
    "        ldata.append(train_predict(clf, X_train[:size], y_train[:size], X_test, y_test))\n",
    "\n",
    "pd.set_option('max_rows', 100)\n",
    "pd.set_option('expand_frame_repr', False)\n",
    "\n",
    "cols = ['CLF','QTD','Tempo_Treinamento','T_Est_Treino','T_Est_Teste','F1_Treino','F1_Teste']\n",
    "df = pd.DataFrame(data = ldata, columns=cols)\n",
    "print df\n",
    "\n",
    "df_mean = df.groupby(['CLF'],sort='F1_Teste').mean()\n",
    "df_mean.columns = ['Média','Tempo_Treinamento','T_Est_Treino','T_Est_Teste','F1_Treino',\\\n",
    "                    'F1_Teste'] \n",
    "print df_mean\n",
    "\n",
    "df_max = df.groupby(['CLF'],sort='F1_Teste').max()\n",
    "df_max.columns = ['Máximo','Tempo_Treinamento','T_Est_Treino','T_Est_Teste','F1_Treino',\\\n",
    "                    'F1_Teste'] \n",
    "print df_max, '\\n'\n",
    "\n",
    "print clf_C , '\\n'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resultados Tabulados\n",
    "Edite a célula abaixo e veja como a tabela pode ser desenhada em [Markdown](https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet#tables). Você deve salvar seus resultados abaixo nas tabelas fornecidas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Classificador 1 - GaussianNB**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |  0.0000              |  0.0000                     | 0.553191                   |          0.612245          |\n",
    "| 200                                |  0.0000              |  0.0000                     | 0.829630                   |         0.766917          |\n",
    "| 300                                |  0.0000              |  0.0000                     | 0.792176                   |        0.738462          |\n",
    "\n",
    "** Classificador 2 - DecisionTreeClassifier**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |   0.0000             | 0.0000                      | 1.0000                     |         0.770370           |\n",
    "| 200                                |   0.0160             | 0.0000                      | 1.0000                     |         0.725806           |\n",
    "| 300                                |   0.0000             | 0.0000                      | 1.0000                     |        0.666667           |\n",
    "\n",
    "** Classificador 3 - SVC**  \n",
    "\n",
    "| Tamanho do Conjunto de Treinamento | Tempo de Treinamento | Tempo de Estimativa (teste) | Pontuação F1 (treinamento) | Pontuação F1 (teste) |\n",
    "| :--------------------------------: | :------------------: | :-------------------------: | :------------------------: | :------------------: |\n",
    "| 100                                |  0.0000              | 0.0000                      | 0.795181                   |        0.805031      |\n",
    "| 200                                |  0.0000              | 0.0000                      | 0.805970                   |          0.805031      |\n",
    "| 300                                |  0.0160              | 0.0000                      | 0.802395                   |          0.805031      |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Escolhendo o Melhor Modelo\n",
    "Nesta seção final, você irá escolher dos três modelos de aprendizagem supervisionada o *melhor* para utilizar os dados dos estudantes. Você então executará um busca em matriz otimizada para o modelo em todo o conjunto de treinamento (`X_train` e `y_train`) ao calibrar pelo menos um parâmetro, melhorando em comparação a pontuação F<sub>1</sub> do modelo não calibrado. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 3 - Escolhendo o Melhor Modelo\n",
    "*Baseando-se nos experimentos que você executou até agora, explique em um ou dois parágrafos ao conselho de supervisores qual modelo que você escolheu como o melhor. Qual modelo é o mais apropriado baseado nos dados disponíveis, recursos limitados, custo e desempenho?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "Como se pode observar pelos resultados, o melhor modelo entre os três foi o SVM (SVC no SKLEARN). Pois obteve o F1 máximo de 80% e F1 médio de também 80% durante o teste. Isso contra os 77% de F1 máximo da Árvore de decisão e 76% de F1 do GaussianNB. Mas na média, obtiveram os valores de 72% e 70% de F1, respectivamente. Em termos de desempenho, o modelo GaussianNB obteve melhores resultados no caso do treinamento e o pior, como era esperado, foi o SVM. Em relação ao testes os três modelos obtiveram ótimos desempenhos.  \n",
    "\n",
    "De forma geral, os resultados mostram que essa configuração de execução não garante que os modelos aprendam de forma consistente. Isso pode ser explicado ou pela falta de calibração dos modelos, ou pela não utilização de validação cruzada ou pela forma como os dados se apresentam de forma que os modelos não conseguem absorver sua complexidade, ou até pela tamanho do conjunto de dados, o que faz com que os modelos tendem a dar pouco atenção aos dados (como no caso do GaussianNB) ou dar muita atenção a eles (no caso da Árvore de decisão).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 4 – O Modelo para um Leigo\n",
    "*Em um ou dois parágrafos, explique para o conselho de supervisores, utilizando termos leigos, como o modelo final escolhido deve trabalhar. Tenha certeza que você esteja descrevendo as melhores qualidades do modelo, por exemplo, como o modelo é treinado e como ele faz uma estimativa. Evite jargões técnicos ou matemáticos, como descrever equações ou discutir a implementação do algoritmo.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "O modelo SVM (Suport Vector Machine), de forma geral e simples, separa os dados de um conjunto de dados linearmente, cada parte com um rótulo. Por exemplo, uma parte pode ser rotulada com os dados considerados verdadeiros e a outra como falso, para uma classificação binária. Isso é visto na figura abaixo. Nessa figura vemos os dados distribuídos num plano e uma linha separa os dados em dois grupos, os dois pontos vermelhos e dos pontos azuis. \n",
    "\n",
    "![Título da imagem](./svm1.png)\n",
    "\n",
    "Para se alcançar a melhor linha que separa de forma mais precisa os dados nos dois grupos faz-se necessário treinar o SVM e ajustá-lo. O diferencial do SVM é que durante o treinamento busca-se encontrar a melhor linha capaz de separar os dados dentre infinitas possibilidades, conforme a figura seguinte. Nesta figura, pode-se verificar que a melhor linha de corte é aquela que busca maximizar a margem de seperação (as distâncias entre as linhas b11 e b12 e entre b21 e b22). Neste caso, a linha B1 apresenta uma melhor margem de separação dos dados em relação a linha B2.\n",
    "\n",
    "![Título da imagem](./svm3.png)\n",
    "\n",
    "Além disso o SVM é capaz de lidar com separações dos dados de forma não linear, trabalhando com dimensoões maiores, ou seja, consegue lidar com uma grande quantidade de atributos. Nessa última figura é possivel ver a curva que separa os pontos azuis dos pontos vermelho. Essa característica é um grande diferencial do SVM em relação a outros modelos.\n",
    "\n",
    "![Título da imagem](./svm2.png)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementação: Calibrando o Modelo\n",
    "Calibre o modelo escolhido. Utilize busca em matriz (`GridSearchCV`) com, pelo menos, um parâmetro importante calibrado com, pelo menos, 3 valores diferentes. Você vai precisar utilizar todo o conjunto de treinamento para isso. Na célula de código abaixo, você deve implementar o seguinte:\n",
    "- Importe [`sklearn.grid_search.gridSearchCV`](http://scikit-learn.org/stable/modules/generated/sklearn.grid_search.GridSearchCV.html) e [`sklearn.metrics.make_scorer`](http://scikit-learn.org/stable/modules/generated/sklearn.metrics.make_scorer.html).\n",
    "- Crie o dicionário de parâmetros que você deseja calibrar para o modelo escolhido.\n",
    " - Examplo: `parameters = {'parameter' : [list of values]}`.\n",
    "- Inicialize o classificador que você escolheu e armazene-o em `clf`.\n",
    "- Crie a função de pontuação F<sub>1</sub> utilizando `make_scorer` e armazene-o em `f1_scorer`.\n",
    " - Estabeleça o parâmetro `pos_label` para o valor correto!\n",
    "- Execute uma busca em matriz no classificador `clf` utilizando o `f1_scorer` como método de pontuação e armazene-o em `grid_obj`.\n",
    "- Treine o objeto de busca em matriz com os dados de treinamento (`X_train`, `y_train`) e armazene-o em `grid_obj`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=10.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=3, gamma='auto', kernel='linear',\n",
      "  max_iter=-1, probability=False, random_state=0, shrinking=True,\n",
      "  tol=0.001, verbose=False) \n",
      "\n",
      "Melhor Score = 0.818269550555\n",
      "Melhores parâmetros =  {'kernel': 'linear', 'C': 10.0} \n",
      "\n",
      "O modelo calibrado tem F1 de 0.8291 no conjunto de treinamento.\n",
      "O modelo calibrado tem F1 de 0.8105 no conjunto de teste.\n"
     ]
    }
   ],
   "source": [
    "# TODO: Importe 'GridSearchCV' e 'make_scorer'\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn import grid_search\n",
    "\n",
    "# TODO: Crie a lista de parâmetros que você gostaria de calibrar\n",
    "parameters = {    \n",
    "    'kernel': ['rbf','linear'],     \n",
    "    'C': [0.001,0.01,0.1, 1.0, 10.0,100.0]\n",
    "} \n",
    "\n",
    "# TODO: Inicialize o classificador\n",
    "clf = svm.SVC(random_state=0)\n",
    "\n",
    "# TODO: Faça uma função de pontuação f1 utilizando 'make_scorer' \n",
    "f1_scorer = make_scorer(f1_score,pos_label='yes')\n",
    "\n",
    "# TODO: Execute uma busca em matriz no classificador utilizando o f1_scorer como método de pontuação\n",
    "grid_obj = grid_search.GridSearchCV(clf, parameters,scoring=f1_scorer,cv=2)\n",
    "\n",
    "# TODO: Ajuste o objeto de busca em matriz para o treinamento de dados e encontre os parâmetros ótimos\n",
    "grid_obj = grid_obj.fit(X_train, y_train)\n",
    "\n",
    "# Get the estimator\n",
    "clf = grid_obj.best_estimator_\n",
    "print clf,'\\n'\n",
    "print \"Melhor Score =\", grid_obj.best_score_\n",
    "print \"Melhores parâmetros = \", grid_obj.best_params_,'\\n'\n",
    "\n",
    "# Reporte a pontuação final F1 para treinamento e teste depois de calibrar os parâmetros\n",
    "#print \"Tuned model has a training F1 score of {:.4f}.\".format(predict_labels(clf, X_train, y_train))\n",
    "f1, t = predict_labels(clf, X_train, y_train)\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de treinamento.\".format(f1)\n",
    "f1, t = predict_labels(clf, X_test, y_test)\n",
    "print \"O modelo calibrado tem F1 de {:.4f} no conjunto de teste.\".format(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questão 5 - Pontuação F<sub>1</sub> Final\n",
    "*Qual é a pontuação F<sub>1</sub> do modelo final para treinamento e teste? Como ele se compara ao modelo que não foi calibrado?*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resposta: **\n",
    "\n",
    "O SVM calibrado obteve 82% de F1 no treinamento e 81% de F1 no teste. Os melhores parâmetros encnotrados pela busca para calibrar o SVM foram Kernel = linear e C = 10.0. Os resultados obtiveram uma leve melhora após a normalização dos dados na fase de processamento dos dados das colunas do conjunto de dados.\n",
    "\n",
    "Comparando com o SVM não calibrado: em relaçao ao teste, houve uma melhora em torno de 1% em relação ao F1 do SVM não calibrado, tanto no valor médio quando no valor máximo (conjunto de treino de tamanho 300). Em relação ao treino, houve um aumento de 2% de F1, tanto na média quanto no valor máximo. \n",
    "\n",
    "Isso mostra que houve ganhos no uso de grid search para se obter os parâmetros que dão melhores resultados ao SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Nota**: Uma vez que você completou todas as implementações de código e respondeu todas as questões acima com êxito, você pode finalizar seu trabalho exportando o iPython Nothebook como um document HTML. Você pode fazer isso utilizando o menu acima e navegando para  \n",
    "**File -> Download as -> HTML (.html)**. Inclua a documentação final junto com o notebook para o envio do seu projeto."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
